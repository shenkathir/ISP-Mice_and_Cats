{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is just to transform the CalMS21 dataset into .pkl files which will be used by 'Creating_Inputs_for_models.ipynb' file"
      ],
      "metadata": {
        "id": "vIwblwrM6TV8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "wdbLKpKG4Lnh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "yxfyV1qb4Lni",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Download and unzip the data\n",
        "import os, requests, zipfile\n",
        "\n",
        "fname = 'task1_classic_classification.zip'\n",
        "url = \"https://data.caltech.edu/records/s0vdx-0k302/files/task1_classic_classification.zip?download=1\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "else:\n",
        "  print('Data have already been downloaded!!!')\n",
        "\n",
        "if not os.path.exists('task1_classic_classification'):\n",
        "  # Unzip the file\n",
        "  with zipfile.ZipFile(fname, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "\n",
        "# Download the script\n",
        "fname = 'calms21_convert_to_npy.py'\n",
        "url = \"https://data.caltech.edu/records/s0vdx-0k302/files/calms21_convert_to_npy.py?download=1\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "MRCB-p-m4Lni",
        "outputId": "d9d36948-55e0-4681-9cc3-c910cf9b292d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ./calms21_task1_train\n",
            "Saving ./calms21_task1_test\n"
          ]
        }
      ],
      "source": [
        "!python calms21_convert_to_npy.py  --input_directory '.' --output_directory '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "x0zulBeE4Lnj"
      },
      "outputs": [],
      "source": [
        "def load_task1_data(data_path):\n",
        "  \"\"\"\n",
        "  Load data for task 1:\n",
        "      The vocaubulary tells you how to map behavior names to class ids;\n",
        "      it is the same for all sequences in this dataset.\n",
        "  \"\"\"\n",
        "  data_dict = np.load(data_path, allow_pickle=True).item()\n",
        "  dataset = data_dict['annotator-id_0']\n",
        "  # Get any sequence key.\n",
        "  sequence_id = list(data_dict['annotator-id_0'].keys())[0]\n",
        "  vocabulary = data_dict['annotator-id_0'][sequence_id]['metadata']['vocab']\n",
        "  return dataset, vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "OAJ_Y8454Lnj"
      },
      "outputs": [],
      "source": [
        "training_data, vocab = load_task1_data('./calms21_task1_train.npy')\n",
        "test_data, _ = load_task1_data('./calms21_task1_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a Dictionary that maps recordings to arrays of shape (num_frames, num_keypoints, num_dimensions) for resident and intruder mouse\n",
        "## This will be the 'coordinates' input for the keypoint-moseq model\n",
        "\n",
        "coordinates_resident = {}\n",
        "confidences_resident = {}\n",
        "coordinates_intruder = {}\n",
        "confidences_intruder = {}\n",
        "annotations = {}\n",
        "\n",
        "for i in training_data.keys():\n",
        "\n",
        "  coord_data = training_data[i]['keypoints']\n",
        "  conf_data = training_data[i]['scores']\n",
        "\n",
        "  reshaped_coord_data_res = np.transpose(coord_data[:,0,:,:], (0,2,1))\n",
        "  reshaped_coord_data_intr = np.transpose(coord_data[:,1,:,:], (0,2,1))\n",
        "  reshaped_conf_data_res = conf_data[:,0,:]\n",
        "  reshaped_conf_data_intr = conf_data[:,1,:]\n",
        "\n",
        "  coordinates_resident['m'+i[18:20]] = reshaped_coord_data_res\n",
        "  coordinates_intruder['m'+i[18:20]] = reshaped_coord_data_intr\n",
        "  confidences_resident['m'+i[18:20]] = reshaped_conf_data_res\n",
        "  confidences_intruder['m'+i[18:20]] = reshaped_conf_data_intr\n",
        "  annotations['m'+i[18:20]] = training_data[i]['annotations']\n"
      ],
      "metadata": {
        "id": "somy9cxJ-TTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQFM_3IieJxQ",
        "outputId": "c2798dce-ce89-4d8f-86ad-c73d5994b232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exporting the data files:\n",
        "import pickle\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/NMA_Project/'\n",
        "\n",
        "with open(folder_path+'coordinates_resident.pkl', 'wb') as file:\n",
        "    pickle.dump(coordinates_resident, file)\n",
        "with open(folder_path+'confidences_resident.pkl', 'wb') as file:\n",
        "    pickle.dump(confidences_resident, file)\n",
        "with open(folder_path+'coordinates_intruder.pkl', 'wb') as file:\n",
        "    pickle.dump(coordinates_intruder, file)\n",
        "with open(folder_path+'confidences_intruder.pkl', 'wb') as file:\n",
        "    pickle.dump(confidences_intruder, file)\n",
        "with open(folder_path+'annotations.pkl', 'wb') as file:\n",
        "    pickle.dump(annotations, file)\n",
        "\n",
        "print(f'Dictionary exported to {folder_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClD9kLpTcVLr",
        "outputId": "caf6d910-8f71-4995-cf7e-3799606cc43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary exported to /content/drive/MyDrive/NMA_Project/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}